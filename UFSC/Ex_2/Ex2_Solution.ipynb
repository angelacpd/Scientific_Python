{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: **Angela Crepaldi**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Universidade Federal de Santa Catarina<br>\n",
    "Departamento de Engenharia Elétrica e Eletrônica<br>\n",
    "EEL7514/EEL7513 - Introdução ao Aprendizado de Máquina\n",
    "$\\newcommand{\\bX}{\\mathbf{X}}$\n",
    "$\\newcommand{\\bw}{\\mathbf{w}}$\n",
    "$\\newcommand{\\by}{\\mathbf{y}}$\n",
    "$\\newcommand{\\bx}{\\mathbf{x}}$\n",
    "$\\newcommand{\\RR}{\\mathbb{R}}$\n",
    "\n",
    "\n",
    "# Exercício 2: Regressão Linear\n",
    "\n",
    "Neste exercício você irá treinar um modelo de regressão linear e o usará para fazer predições. Além disso, você investigará a adição de novos atributos e a necessidade de regularização."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conjunto de dados\n",
    "\n",
    "Para facilitar a análise, o conjunto de dados utilizado neste exercício possui um único atributo $x \\in \\RR$ (e um valor-alvo $y \\in \\RR$). Além desta peculiaridade, é importante ressaltar duas grandes diferenças em relação ao que se encontra em problemas reais:\n",
    "- O conjunto de dados é sintético, isto é, gerado por simulação;\n",
    "- O conjunto de treinamento tem tamanho **muito menor** que os conjuntos de validação e teste.\n",
    "\n",
    "A razão para esta escolha é que um conjunto de treinamento pequeno nos permitirá observar mais facilmente o fenômeno de overfitting, enquanto conjuntos de validação e teste suficientemente grandes nos permitirá ter confiança na estimativa de desempenho do modelo medida nestes conjuntos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def gen_data(n_samples, x_scale=[0,1], noise=0.5):\n",
    "    '''Generate univariate regression dataset'''\n",
    "    x = np.sort(np.random.rand(n_samples))\n",
    "    y = 6*(-1/6 + x + (x > 1/3)*(2/3-2*x) + (x > 2/3)*(2*x-4/3)) + noise*np.random.randn(n_samples)\n",
    "    x = x_scale[0] + (x_scale[1]-x_scale[0])*x\n",
    "    X = x.reshape(-1,1)\n",
    "    return X, y\n",
    "\n",
    "def plot_data(X, y):\n",
    "    '''Plot univariate regression dataset'''\n",
    "    assert len(X.shape) == 2 and len(y.shape) == 1\n",
    "    plt.plot(X[:,0],y,'b.'); plt.xlabel('x'); plt.ylabel('y');\n",
    "    return\n",
    "\n",
    "def plot_prediction(model, X, y, n_points=100):\n",
    "    '''Plot dataset and predictions for a univariate regression model'''\n",
    "    plot_data(X,y)\n",
    "    if n_points is not None:\n",
    "        xx = np.linspace(X.min(),X.max(),n_points)\n",
    "        yy = model.predict(xx.reshape(-1,1))\n",
    "        plt.plot(xx,yy,'r-')\n",
    "    y_pred = model.predict(X)\n",
    "    plt.plot(X[:,0],y_pred,'r.')\n",
    "    plt.legend(['True', 'Predicted'])\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O conjunto de dados pode ser gerado e visualizado pelos comandos abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 1) (30,)\n",
      "(1000, 1) (1000,)\n",
      "(1000, 1) (1000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(2019*2)\n",
    "X, y = gen_data(n_samples=30)\n",
    "X_val, y_val = gen_data(n_samples=1000)\n",
    "X_test, y_test = gen_data(n_samples=1000)\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "# Plot only the training data!\n",
    "plot_data(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Regressão linear simples\n",
    "\n",
    "\n",
    "1. Treine um modelo de regressão linear simples, $\\hat{y} = w_0 + w_1 x$, sobre o conjunto de treinamento\n",
    "- Calcule o erro quadrático médio (MSE) da predição sobre o conjunto de treinamento e sobre o conjunto de teste\n",
    "- Trace o gráfico da predição sobre o conjunto de treinamento\n",
    "- Você diria que o modelo treinado está sofrendo de underfitting, overfitting ou nenhum dos dois? Explique.\n",
    "- (OPCIONAL) Experimente também a função `model.score()` do sklearn. Qual a relação entre este valor e o MSE? É possível calcular um a partir do outro? Como?\n",
    "\n",
    "#### Funções úteis:\n",
    "```python\n",
    "sklearn.linear_model.LinearRegression()\n",
    "sklearn.metrics.mean_squared_error()\n",
    "plot_prediction() # fornecida acima\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Adicionando atributos (regressão linear com múltiplas variáveis)\n",
    "\n",
    "Agora, estenderemos o modelo de regressão linear adicionando atributos polinomiais de grau até $d$, isto é, o modelo será dado por $\\hat{y} = w_0 + w_1 x + w_2 x^2 + \\cdots + w_d x^d$. Note que esse modelo possui um hiperparâmetro, $d$, que precisa ser determinado. **A boa prática recomenda nunca utilizar o conjunto de teste até que todos os hiperparâmetros sejam escolhidos**, utilizando, ao invés disso, o conjunto de validação.\n",
    "\n",
    "1. Adicione atributos polinomiais ao modelo de regressão linear, escolha algum valor de $d$ e treine o modelo\n",
    "- Calcule o erro quadrático médio (MSE) da predição sobre o conjunto de treinamento e sobre o **conjunto de validação**\n",
    "- Trace o gráfico da predição sobre o conjunto de treinamento\n",
    "- Repita os passos acima experimentando outros valores de $d$. O que você observa?\n",
    "- Especificamente, para o caso $d=12$, você diria que o modelo está sofrendo de underfitting, overfitting ou nenhum dos dois?\n",
    "\n",
    "#### Funções úteis:\n",
    "```python\n",
    "sklearn.preprocessing.PolynomialFeatures()\n",
    "sklearn.pipeline.make_pipeline()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Busca de hiperparâmetros\n",
    "\n",
    "6. Trace um gráfico do MSE de treinamento e de validação em função do grau $d$. Se necessário, ajuste a escala vertical para melhor visualização.\n",
    "- Comente sobre o que você observa no gráfico. Em particular, explique o comportamento das duas curvas e por que esse comportamento era esperado.\n",
    "- Determine o valor de $d$ que minimiza o erro no conjunto de validação.\n",
    "- Para este valor de $d$, calcule o MSE de treinamento, de validação **e de teste** e trace o gráfico da predição sobre o conjunto de treinamento.\n",
    "- (OPCIONAL) O erro de validação parece representativo do erro de teste? O que você acha que aconteceria se o conjunto de validação fosse significativamente menor (por exemplo, com 30 amostras ao invés de 1000)?\n",
    "\n",
    "#### Funções úteis:\n",
    "```python\n",
    "np.arange()\n",
    "np.zeros() # útil para pré-alocação de vetores\n",
    "for i in range(len(v)): # percorre os elementos de v\n",
    "plt.ylim()\n",
    "np.argmin()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 3. Regularização\n",
    "\n",
    "Agora, adicionaremos regularização $\\ell_2$ ao modelo, o que introduz mais um hiperparâmetro, o parâmetro de regularização $\\lambda$.\n",
    "\n",
    "1. Retornando ao modelo com $d=12$, agora com regularização $\\ell_2$ (*ridge regression*), experimente alguns valores de $\\lambda$ e observe os resultados no gráfico da predição sobre o conjunto de treinamento. (Você logo perceberá a necessidade de usar $\\lambda \\ll 1$.) Em particular, o que acontece quando $\\lambda$ é comparativamente grande?\n",
    "- Trace um gráfico do MSE de treinamento e de validação em função de $\\log \\lambda$.\n",
    "- Comente sobre o que você observa no gráfico. Em particular, explique o comportamento das duas curvas e por que esse comportamento era esperado.\n",
    "- Determine o valor de $\\lambda$ que minimiza o erro no conjunto de validação.\n",
    "- Para este valor de $\\lambda$, calcule o MSE de treinamento, de validação e de teste e trace o gráfico da predição sobre o conjunto de treinamento.\n",
    "- A partir destes resultados, comente sobre o efeito da regularização em um modelo com capacidade elevada comparativamente ao tamanho do conjunto de treinamento.\n",
    "- (OPCIONAL) O que você acha que ocorreria se o conjunto de treinamento fosse relativamente grande (por exemplo, com 1000 amostras ao invés de 30)? Ainda seria importante regularizar?\n",
    "\n",
    "#### Dicas\n",
    "\n",
    "- Não utilize `lambda` como nome de variável, pois no Python `lambda` é uma palavra reservada (operador para criar funções anônimas). Uma sugestão é abreviar para `lamb`.\n",
    "\n",
    "- Funções úteis:\n",
    "```python\n",
    "sklearn.linear_model.Ridge()\n",
    "np.linspace()\n",
    "np.exp()\n",
    "np.log()\n",
    "```\n",
    "Note que a função `Ridge()` utiliza `alpha` (ao invés de $\\lambda$) como parâmetro de regularização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## (OPCIONAL) Busca de hiperparâmetros (2)\n",
    "\n",
    "8. Determine o par $(d,\\lambda)$ que minimiza o erro no conjunto de validação.\n",
    "- Para estes valores de $d$ e $\\lambda$, calcule o MSE de treinamento, de validação e de teste e trace o gráfico da predição sobre o conjunto de treinamento.\n",
    "- Compare o erro de teste encontrado com o resultante da melhor escolha de $d$ sem regularização.\n",
    "\n",
    "#### Dicas\n",
    "- Uma forma de implementar a busca pelo par $(d,\\lambda)$ é organizar a implementação em dois loops, primeiramente em $d$ e em seguida em $\\lambda$.\n",
    "- Pode ser conveniente encapsular o loop interno (busca por $\\lambda$) em uma função que tem como entrada $d$ e retorna $\\lambda$.\n",
    "- Os códigos já desenvolvidos podem ser reutilizados com poucas adaptações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 4. Implementação em Python\n",
    "\n",
    "Finalmente, você irá escrever sua própria implementação dos modelos acima, usando uma interface parcialmente compatível com a biblioteca `sklearn`. Além das funções `fit()` e `predict()`, a classe do modelo deverá conter uma função `mse()` para cálculo do MSE (ao invés da função `score()` do `sklearn`).\n",
    "\n",
    "É suficiente implementar um modelo de regressão linear com atributos polinomiais de grau $d$ e regularização $\\ell_2$ com parâmetro $\\lambda$; caso se deseje um modelo sem atributos polinomiais (linear na variável de entrada) ou sem regularização, é suficiente fazer $d=1$ ou $\\lambda=0$, respectivamente.\n",
    "\n",
    "1. Complete a classe abaixo, preenchendo as linhas indicadas (ou fique à vontade para reimplementar da forma que desejar).\n",
    "- Teste-a com os comandos da célula seguinte, para garantir que sua implementação está correta.\n",
    "- (OPCIONAL) Para este conjunto de dados, o que ocorre quando usamos $d \\geq 10$ e $\\lambda=0$? Por que isso ocorre? Isto deixa de ocorrer se usarmos $\\lambda=10^{-12}$? Por quê?\n",
    "\n",
    "#### Funções úteis:\n",
    "```python\n",
    "np.ones()\n",
    "np.c_[]\n",
    "np.diag()\n",
    "np.r_[]\n",
    "np.linalg.inv()\n",
    "np.linalg.solve()\n",
    "np.mean()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-1cd7c94da698>, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-1cd7c94da698>\"\u001b[1;36m, line \u001b[1;32m11\u001b[0m\n\u001b[1;33m    X_new = ???\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class Model():\n",
    "    # Univariate linear regression with polinomial features and L2 regularization\n",
    "    def __init__(self, d=1, lamb=0):\n",
    "        # Initialization\n",
    "        self.d = d\n",
    "        self.lamb = lamb\n",
    "        return\n",
    "    \n",
    "    def _add_powers(self, X):\n",
    "        # Add powers of X (including a column of ones)\n",
    "        X_new = ???\n",
    "        for i in range(1,self.d+1):\n",
    "            X_new = ???\n",
    "        return X_new\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X = self._add_powers(X)\n",
    "        L = ???\n",
    "        assert np.linalg.matrix_rank(X.T @ X + self.lamb*L) == X.shape[1], 'Singular matrix'\n",
    "        self.w = ???\n",
    "        return\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = self._add_powers(X)\n",
    "        y_pred = ???\n",
    "        return y_pred\n",
    "    \n",
    "    def mse(self, X, y):\n",
    "        J = ???\n",
    "        return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scikit-learn\n",
    "model = make_pipeline(PolynomialFeatures(4, include_bias=False),Ridge(1e-5))\n",
    "model.fit(X,y)\n",
    "ridge = model.steps[1][1]\n",
    "w = np.r_[ridge.intercept_, ridge.coef_]\n",
    "print('w =',w)\n",
    "\n",
    "# own implementation\n",
    "model = Model(d=4, lamb=1e-5)\n",
    "model.fit(X,y)\n",
    "print('w =',model.w)\n",
    "print('Training MSE  : %f' % model.mse(X,y));\n",
    "print('Validation MSE: %f' % model.mse(X_val,y_val));\n",
    "plot_prediction(model, X, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
